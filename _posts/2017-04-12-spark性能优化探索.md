---
layout: post
title:  Spark 性能优化参考
date:   2017-04-12 09:54:07 +08:00
category: Spark
tags: Spark 性能优化
comments: true
---
* content
{:toc}
Spark 性能优化参考

# Spark 性能优化参考

## 一、资源优化

> spark官方的：

```
/bin/spark-submit
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode cluster \  # can be client for client mode
--driver-memory 1G \ # 配置driver的内存（影响不大）
--executor-cores 4 \ # 配置每个executor的cpu core数量
--executor-memory 4G \ # 配置每个executor的内存大小
--num-executors 4 \ # 配置executor的数量
/path/to/examples.jar \
1000
```
### 1.deploy-mode 怎么设置？


### 2.executor-memory 怎么设置？

#### 2.1 cache。
如果需要对RDD进行cache，那么更多的内存，就可以缓存更多的数据，将更少的数据写入磁盘，甚至不写入磁盘。

#### 2.2 Shuffle。

对于shuffle操作，reduce端，会需要内存来存放拉去的数据，并进行聚合，如果内存不够，也会写入磁盘。executor有更多内存,就可以少写入磁盘，减少磁盘IO。

#### 2.3 GC
对于task的执行，可能会创建很多对象。 如果内存比较小，可能会频繁导致JVM堆内存满，导致GC，minor GC和full GC。（速度很慢）
内存加大以后，带来更少的GC，避免了速度变慢，速度变快了！


### 3.num-executors 怎么设置？

	增加executor 提高并行计算能力。

> 3个executor ，每个executor有2个core 那么同时能够并行执行的task就是6个.6个执行完以后，再换下一批6个task。
> 现在增加到10个executor，可同时并行20个task

### 4.executor-cores 

	增加executor 的core 提高并行计算能力

> 20个executor，2个core/e 能够并行执行 40个task
> 每个executor 增加到5个。能够并行执行100个task。
> 提升2.5倍

## 二、并行度优化


### WHAT:

> spark作业中，各个stage的task的数量

### WHY：

`资源浪费`：资源分配充足的情况下，并行度没有与资源相匹配，导致资源浪费。



50个executor 每个executor 3个Core 的情况下。
总共150个cpu core 可以并行运行。
但是,这个stage 只有100个task（并行度）。有50个core就被浪费了。

`官方推荐`： task数目（并行度） 设置为core 数目的 2 ~ 3倍。因为： 有些task可能运行快一点，这几个运行完就空闲了，导致浪费。 2~3 倍 ，task 运行完，其他task 马上补过来。尽量让cpu core 不空闲。提升效率。

### HOW：

```
SparkSession.builder().config("spark.defalut.parallelism","500")

df.repartition(500) 

```
## 二、RDD/DataSet 优化

### HOW：
1. 复用RDD/DataSet 供后面的RDD计算反复使用
2. 公共的RDD 一定要持久化
3. 持久化的时候 进行序列化
4. 资源充足的情况下，双副本机制

### TODO


## 算子优化

```

```
### 算子优化

### 

### 累加器、广播


## Shuffle 优化 


# 配置优化


